{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7227ddd9-aaba-4c92-9c6a-d544713d8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'df_car' loaded successfully.\n",
      "Feature Engineering Complete.\n",
      "Columns after cleanup: ['Selling_Price', 'Present_Price', 'Kms_Driven', 'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner', 'Years_of_Service']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "# --- FIX: Load the DataFrame (df_car) first ---\n",
    "# Assuming 'car.csv' is in the 'data/' subdirectory relative to your notebook\n",
    "# NOTE: Update the path if your notebook is not in 'notebooks/'\n",
    "try:\n",
    "    df_car = pd.read_csv(\"../data/car.csv\")\n",
    "except FileNotFoundError:\n",
    "    # If the relative path fails, use the absolute path from the previous attempts\n",
    "    file_path = \"C:\\\\Users\\\\LENOVO\\\\Documents\\\\My Projects\\\\ShadowFox\\\\Car_Price_Prediction\\\\data\\\\car.csv\"\n",
    "    df_car = pd.read_csv(file_path)\n",
    "\n",
    "print(\"DataFrame 'df_car' loaded successfully.\")\n",
    "\n",
    "# 1. Feature Engineering: Derive 'Years_of_Service'\n",
    "current_year = 2025\n",
    "df_car['Years_of_Service'] = current_year - df_car['Year']\n",
    "\n",
    "# 2. Drop irrelevant or redundant columns\n",
    "df_car.drop(['Car_Name', 'Year'], axis=1, inplace=True)\n",
    "\n",
    "print(\"Feature Engineering Complete.\")\n",
    "print(\"Columns after cleanup:\", df_car.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147ce6a1-0781-43c3-afca-5375e44c7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 'years_vs_price_scatter.png' and 'present_vs_price_scatter.png' in the visuals folder.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Plot 1: Selling Price vs. Age of Car ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x='Years_of_Service', y='Selling_Price', data=df_car)\n",
    "plt.title('Selling Price vs. Age of Car (Years of Service)')\n",
    "# Ensure the path matches your structure (assuming /Car_Price_Prediction/visuals/)\n",
    "plt.savefig('../visuals/years_vs_price_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "# --- Plot 2: Selling Price vs. Showroom Price (Present_Price) ---\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x='Present_Price', y='Selling_Price', data=df_car)\n",
    "plt.title('Selling Price vs. Showroom Price (Present_Price)')\n",
    "plt.savefig('../visuals/present_vs_price_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Generated 'years_vs_price_scatter.png' and 'present_vs_price_scatter.png' in the visuals folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ac4071-80a8-4c14-b310-bbf77265cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing (Encoding and Splitting) Complete.\n",
      "Features after Encoding: ['Present_Price', 'Kms_Driven', 'Owner', 'Years_of_Service', 'Fuel_Type_Diesel', 'Fuel_Type_Petrol', 'Seller_Type_Individual', 'Transmission_Manual']\n",
      "Training Samples: 240\n",
      "Testing Samples: 61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separate features (X) and target (y)\n",
    "X = df_car.drop('Selling_Price', axis=1)\n",
    "y = df_car['Selling_Price']\n",
    "\n",
    "# 2. Apply One-Hot Encoding to categorical features, dropping the first category to avoid multicollinearity\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 3. Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data Preprocessing (Encoding and Splitting) Complete.\")\n",
    "print(f\"Features after Encoding: {X.columns.tolist()}\")\n",
    "print(f\"Training Samples: {len(X_train)}\")\n",
    "print(f\"Testing Samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ecf861-13bd-4812-98af-7ef11d0a1f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Tuning with Randomized Search (This may take a moment)...\n",
      "\n",
      "Hyperparameter Tuning Complete.\n",
      "Best Parameters Found: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25}\n",
      "\n",
      "--- Final Model Evaluation ---\n",
      "Model: Random Forest Regressor (Hyperparameter Tuned)\n",
      "R-squared (R2) Score: 0.9423\n",
      "Root Mean Squared Error (RMSE): 1.1526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- 4.1 Define Hyperparameter Search Space ---\n",
    "# This dictionary defines the range of parameters for the Randomized Search\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "max_features = [1.0, 'sqrt'] # 1.0 is equivalent to 'auto' for Random Forest Regressor\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# --- 4.2 Initialize and Tune Model ---\n",
    "print(\"Starting Hyperparameter Tuning with Randomized Search (This may take a moment)...\")\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize Randomized Search (10 random combinations, 5-fold cross-validation)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 10,  \n",
    "                               cv = 5, \n",
    "                               verbose=0, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1) # Use all processors for speed\n",
    "\n",
    "# Fit/Train the Tuned Model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Use the best model found by the search\n",
    "best_rf_model = rf_random.best_estimator_\n",
    "\n",
    "print(\"\\nHyperparameter Tuning Complete.\")\n",
    "print(\"Best Parameters Found:\", rf_random.best_params_)\n",
    "\n",
    "\n",
    "# --- 4.3 Final Evaluation and Metrics ---\n",
    "# Make predictions using the best model\n",
    "y_pred_tuned = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate Evaluation Metrics\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
    "rmse_tuned = np.sqrt(mse_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
    "\n",
    "print(\"\\n--- Final Model Evaluation ---\")\n",
    "print(f\"Model: Random Forest Regressor (Hyperparameter Tuned)\")\n",
    "print(f\"R-squared (R2) Score: {r2_tuned:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddab0ff7-c601-4017-bdfa-3eeee54bf65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated EDA plots.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot 1: Selling Price vs. Age of Car (Years_of_Service)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x='Years_of_Service', y='Selling_Price', data=df_car)\n",
    "plt.title('Selling Price vs. Age of Car (Years of Service)')\n",
    "# Saves the first plot\n",
    "plt.savefig('../visuals/years_vs_price_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: Selling Price vs. Showroom Price (Present_Price)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x='Present_Price', y='Selling_Price', data=df_car)\n",
    "plt.title('Selling Price vs. Showroom Price (Present_Price)')\n",
    "# Saves the second plot\n",
    "plt.savefig('../visuals/present_vs_price_scatter.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Generated EDA plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1679482c-1d63-486b-bbc9-878fd09a4f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated final model performance plot.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming y_test (actual prices) and y_pred_tuned (predicted prices) exist from Step 4\n",
    "\n",
    "# Plot 3: Actual vs. Predicted Prices (Model Performance Check)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_test, y=y_pred_tuned)\n",
    "# Add ideal prediction line (Red Line)\n",
    "min_val = min(y_test.min(), y_pred_tuned.min())\n",
    "max_val = max(y_test.max(), y_pred_tuned.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ideal Line')\n",
    "plt.title('Actual vs. Predicted Car Selling Prices (Tuned RF)')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.legend()\n",
    "# Saves the third, final plot\n",
    "plt.savefig('../visuals/actual_vs_predicted_prices_tuned.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Generated final model performance plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc9b2a-c778-401c-9635-5fbe5cece39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
